{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia notebook for OCT and holistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Gurobi, JuMP\n",
    "using CSV, DataFrames\n",
    "using LinearAlgebra, Random, Statistics\n",
    "using PyPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CSV.read(\"processed_data.csv\", DataFrame)\n",
    "X = Matrix(select(data, Not([\"setting1\", \"setting2\", \"unitNumber\", \"RUL\"])))\n",
    "y = data[:, \"RUL\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_norm = (X .- minimum(X, dims = 1)) ./ (maximum(X, dims = 1) - minimum(X, dims = 1))\n",
    "y_norm = (y .- minimum(X)) ./ (maximum(y) .- minimum(y));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = IAI.split_data(:regression, X_norm, y_norm, seed = 2, train_proportion = 0.8);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that transforms the matrix input matrix by adding non-linear transformations to all columns\n",
    "function transform_data(X, eps = 0.1)\n",
    "\n",
    "    n, p = size(X) # Store the matrix dimension\n",
    "    # Initiate the transformed matrix with the first feature\n",
    "    Xt = hcat(X[:,1], X[:,1].^2, X[:,1].^0.5, exp.(X[:,1]), log.(abs.(X[:,1]) .+ eps))\n",
    "\n",
    "    # Loop for all other features and concatenate the transformations to the matrix\n",
    "    for i = 2:p\n",
    "        Xt = hcat(Xt, X[:,i], X[:,i].^2, X[:,i].^0.5, exp.(X[:,i]), log.(abs.(X[:,i]) .+ eps))\n",
    "    end\n",
    "\n",
    "    return Xt;\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = names(select(data, Not([\"setting1\", \"setting2\", \"unitNumber\", \"RUL\"])))\n",
    "features_transformed = [pre * f for f in features for pre in [\"\", \"squared_\", \"root_\", \"exp_\", \"log_\"]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that returns a list of feature couples whose correlation exceeds rho\n",
    "function pairwise_correlation(X, rho)\n",
    "\n",
    "    _, p = size(X) # Store the number of features\n",
    "    cor_matrix = cor(X); # Compute the correlation matrix\n",
    "    cor_variables = [] # Initialize an empty list to store all pairwise correlated features couples\n",
    "\n",
    "    for i = 1:p \n",
    "        for j = 1:i-1 # Loop under all values of the lower diagonal of the correlation matrix\n",
    "\n",
    "            if abs(cor_matrix[i,j]) > rho\n",
    "                # If the correlation coefficient of features i and j exceeds rho, append the couple to the list\n",
    "                push!(cor_variables, (i,j))\n",
    "            end\n",
    "            \n",
    "        end\n",
    "    end\n",
    "\n",
    "    return cor_variables;\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "function holistic_regression(X, y, rho, lambda, k, M)\n",
    "\n",
    "    # Create the transformed matrix\n",
    "    X_transformed = transform_data(X);\n",
    "    n, p = size(X) # Store the input matrix size\n",
    "    _, p_tilde = size(X_transformed) # Set the number of features in the transformed matrix\n",
    "    augmentation = Int(p_tilde / p)\n",
    "    # Compute the list of correlated feature couples\n",
    "    HC = pairwise_correlation(X_transformed, rho)\n",
    "\n",
    "    # Create JuMP model\n",
    "    model = Model(Gurobi.Optimizer)\n",
    "    set_optimizer_attribute(model, \"OutputFlag\", 0)\n",
    "\n",
    "    # Introduce model variables\n",
    "    @variable(model, Beta[1:p_tilde])\n",
    "    @variable(model, a[1:p_tilde] >= 0)\n",
    "    @variable(model, z[1:p_tilde], binary = true)\n",
    "\n",
    "    # Robustness term constraint linearization\n",
    "    @constraint(model,[j = 1:p_tilde], Beta[j] <= a[j])\n",
    "    @constraint(model,[j = 1:p_tilde], -Beta[j] <= a[j])\n",
    "\n",
    "    # Big-M integer constraint for sparsity\n",
    "    @constraint(model,[j = 1:p_tilde], Beta[j] <= M*z[j])\n",
    "    @constraint(model,[j = 1:p_tilde], Beta[j] >= -M*z[j])\n",
    "    # Sparsity constraint\n",
    "    @constraint(model, sum(z[j] for j = 1:p_tilde) <= k)\n",
    "\n",
    "    # Non-linear transformations constraint\n",
    "    @constraint(model, [j = 1:p], sum(z[augmentation*(j-1)+i] for i = 1:augmentation) <= 1)\n",
    "\n",
    "    # Pairwise collinearity\n",
    "    @constraint(model, [i = 1:length(HC)], z[HC[i][1]] + z[HC[i][2]] <= 1)\n",
    "\n",
    "    # Implement the objective function of the problem\n",
    "    @objective(model, Min, sum((y[i] - sum(X_transformed[i,j]*Beta[j] for j=1:p_tilde))^2 for i = 1:n) + lambda * sum(a[j] for j = 1:p_tilde))\n",
    "\n",
    "    # Solve the optimization problem\n",
    "    optimize!(model);\n",
    "\n",
    "    Beta, z = JuMP.value.(Beta), Int.(JuMP.value.(z))\n",
    "\n",
    "    y_pred = X_transformed * Beta\n",
    "    r2 = 1 - sum((y_pred .- y).^2) / sum((mean(y) .- y).^2)\n",
    "    print(\"Training R2: $(r2)\")\n",
    "\n",
    "    return Beta, z, r2\n",
    "\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-08-18\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-08-18\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-08-18\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-08-18\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-08-18\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-08-18\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-08-18\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-08-18\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-08-18\n",
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-08-18\n"
     ]
    }
   ],
   "source": [
    "# Specify the holisitic regression problem parameters\n",
    "rho = 0.8\n",
    "lambda = 1\n",
    "k = 10\n",
    "M = 100\n",
    "\n",
    "R2 = []\n",
    "for seed in Vector(1:10)\n",
    "    (X_train, y_train), (X_test, y_test) = IAI.split_data(:regression, X_norm, y_norm, seed = seed, train_proportion = 0.8);\n",
    "    # Compute the holistic regression model\n",
    "    Beta, _ = holistic_regression(X_train, y_train, rho, lambda, k, M);\n",
    "    X_test_transformed = transform_data(X_test);\n",
    "    y_pred = Beta_0 .+ X_test_transformed * Beta;\n",
    "    r2 = 1 - sum((y_pred .- y_test).^2) / sum((mean(y_train) .- y_test).^2)\n",
    "    push!(R2, r2)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-08-18\n",
      "Training R2: 0.69804972093401"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6798049184986299"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = IAI.split_data(:regression, X_norm, y_norm, seed = 1, train_proportion = 0.8);\n",
    "\n",
    "# Compute the holistic regression model\n",
    "Beta, _, _ = holistic_regression(X_train, y_train, rho, lambda, k, M);\n",
    "X_test_transformed = transform_data(X_test);\n",
    "y_pred = X_test_transformed * Beta;\n",
    "r2 = 1 - sum((y_pred .- y_test).^2) / sum((mean(y_train) .- y_test).^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
